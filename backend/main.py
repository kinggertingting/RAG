from ingestion.embedder import Embedder
from vector_store.qdrant_store import QdrantStore
from retrieval.retriever import Retriever
from rerank.cross_encoder import CrossEncoderModel
from rerank.rerank import Reranker
from llm.llm_service import LLMService
from rag.rag_pipeline import RAGPipeline
from ingestion.ingestion_service import IngestionService
from ingestion.loader import Loader
from ingestion.cleaner import Cleaner
from ingestion.chunker import Chunker

from config.settings import *


def main():

    print("ğŸ”„ Loading models...")

    # Core components
    embedder = Embedder(EMBEDDING_MODEL)
    qdrant_store = QdrantStore(QDRANT_HOST, QDRANT_PORT)
    retriever = Retriever(embedder, qdrant_store)
    cross_encoder = CrossEncoderModel(RERANK_MODEL)
    reranker = Reranker(cross_encoder)
    llm_service = LLMService(LLM_MODEL)

    rag = RAGPipeline(retriever, reranker, llm_service)

    # Ingestion components
    loader = Loader()
    cleaner = Cleaner()
    chunker = Chunker()

    ingestion = IngestionService(
        loader,
        cleaner,
        chunker,
        embedder,
        qdrant_store
    )

    print("âœ… System ready!\n")

    while True:
        print("1ï¸âƒ£ Upload file")
        print("2ï¸âƒ£ Ask question")
        print("3ï¸âƒ£ Exit")

        choice = input("> ")

        if choice == "1":
            file_path = input("ğŸ“‚ Nháº­p Ä‘Æ°á»ng dáº«n file: ")

            try:
                ingestion.ingest(file_path)
                print("âœ… Ingestion xong!\n")
            except Exception as e:
                print(f"âŒ Lá»—i: {e}")

        elif choice == "2":
            query = input("ğŸ§  Báº¡n há»i gÃ¬?\n> ")
            print("\nğŸ¤– Äang xá»­ lÃ½...\n")
            answer = rag.run(query)
            print("ğŸ“Œ Tráº£ lá»i:\n")
            print(answer)
            print("\n" + "=" * 50 + "\n")

        elif choice == "3":
            break

        else:
            print("âš ï¸ Chá»n láº¡i.")


if __name__ == "__main__":
    main()